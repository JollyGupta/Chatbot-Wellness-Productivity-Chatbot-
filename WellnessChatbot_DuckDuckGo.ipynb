{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOwuS2ayDCQD"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install/upgrade the package\n",
        "!pip install --upgrade langchain langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW1-TfnOXEiC"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKXfXqIsDDVJ"
      },
      "outputs": [],
      "source": [
        "pip install -U ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh2ORvW8DDZD",
        "outputId": "765c9e42-ec98-4f70-dd64-af29b1752802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We compared 6 popular AI talking head tools on various avatar types (photorealistic, cartoons, non-humanoids, etc) and various types of music ( singing , rapping, acappella, etc). LemonSlice - an AI video model specific for generating expressive, talking avatars. This AI singer tool is the perfect option for those who need to experiment with different vocal effects and styles.This is the top choice tool for both content creators and music producers, perfect for reliable AI voice singing solutions. Top AI music agents in 2025 include Tunee AI , Producer AI , MixAudio (Beta), and AIVA. Each offers unique strengths, from conversational interfaces to professional-grade composition tools . Top AI Singing Tools : Suno. ai â€“ Create full original songs (lyrics + vocals + backing track) from prompts. Synthesizer V â€“ Control pitch, breathiness, vibrato; supports multiple languages and expressive singing . Explore Media.io's powerful AI tools to generate videos, images, and music online for free! All the latest & greatest AI models intergrated in one place.\n"
          ]
        }
      ],
      "source": [
        "# Import the tool\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Initialize the search tool\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Perform a search\n",
        "query = \"Top 3 AI tools for Singer?\"\n",
        "result = search.run(query)   # use .run() instead of .invoke()\n",
        "\n",
        "# Print result\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iRs0RWwNDDek"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "ji4BDCE0DDhR",
        "outputId": "1c897232-3c88-4176-924b-1aee52872ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6e56ec928779d4b3df.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6e56ec928779d4b3df.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Define a simple function to use in Gradio\n",
        "def search_query(query):\n",
        "    return search.run(query)\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=search_query,\n",
        "    inputs=gr.Textbox(label=\"Enter your query\"),\n",
        "    outputs=gr.Textbox(label=\"Search Result\", lines=15)  # increase lines for bigger window\n",
        ")\n",
        "iface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lFfthoSEDDj4"
      },
      "outputs": [],
      "source": [
        "# DUCKDUCK- paragraph\n",
        "# LLM - TOP 3 point to point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ZQcEfpcfec",
        "outputId": "f9d7f842-8346-4e4a-e038-ceb5caad9e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Aug 12, 2025 Â· From generating stems and beats to mastering full tracks, AI is simplifying the creative process while giving musicians more control over their sound. In this guide, weâ€™ll break down the top AI music production tools that are transforming how music is made in 2025. AI is changing. the vocal production game faster than ever. Here's 6 AI vocal tools that'll take your tracks to new levels. Jan 20, 2025 Â· Thereâ€™s been an influx of AI tools for music production recently, and it has gotten tougher to choose between the good and the bad ones. This article saves you the hassle by highlighting some of the best AI tools for music production so you can simply focus on building awesome projects. Comparing AI Music Software: Which Is Right for You? Artificial intelligence is not just augmenting today's music production - it is fundamentally reimagining how musicians create, practice, and interact with sound. From advanced stem separation to natural language synthesis, these tools represent the cutting edge of what is possible when neural networks meet musical creativity. This collection of groundbreaking platforms showcases how AI is... Sep 11, 2025 Â· From generating melodies and lyrics to separating stems and mastering full tracks, these tools save hours of manual work while boosting creativity. The following guide breaks down the top 10 AI tools for music producers, chosen for their reliability, innovative features, and impact on workflow.\"]\n"
          ]
        }
      ],
      "source": [
        "result = search.run(\"Top AI tools for singers\")\n",
        "\n",
        "# Simple extraction: split by lines or numbers\n",
        "tools = [line for line in result.split(\"\\n\") if line.strip()][:3]\n",
        "print(tools)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n54ST7QAdFnA"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-groq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaHkQ7RxcfoR",
        "outputId": "62e13bd4-e794-4f0e-83fb-22055e6eb3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Raw Result ===\n",
            "Aug 12, 2025 Â· From generating stems and beats to mastering full tracks, AI is simplifying the creative process while giving musicians more control over their sound. In this guide, weâ€™ll break down the top AI music production tools that are transforming how music is made in 2025. AI is changing. the vocal production game faster than ever. Here's 6 AI vocal tools that'll take your tracks to new levels. Jan 20, 2025 Â· Thereâ€™s been an influx of AI tools for music production recently, and it has got ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-581552337.py:38: LangChainDeprecationWarning: The method `BaseChatModel.predict_messages` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  summary = llm.predict_messages([HumanMessage(content=prompt_text)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Top 3 List ===\n",
            "Unfortunately, the text doesn't specifically mention AI tools for singers, but rather for music producers in general. However, based on the text, I can infer that some of the tools mentioned may be beneficial for singers. Here are the top 3 AI tools for music production that could be useful for singers, in a simple numbered list:\n",
            "\n",
            "1. AI tools for generating melodies and lyrics\n",
            "2. AI tools for separating stems\n",
            "3. AI tools for mastering full tracks\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "#load_dotenv()  # loads variables from .env\n",
        "load_dotenv(\"/content/.env.txt\")\n",
        "\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it in .env\")\n",
        "\n",
        "\n",
        "# Initialize\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7, max_tokens=500)\n",
        "\n",
        "# Search query\n",
        "query = \"Top AI tools for singers\"\n",
        "raw_result = search.run(query)\n",
        "\n",
        "print(\"=== Raw Result ===\")\n",
        "print(raw_result[:500], \"...\")\n",
        "\n",
        "# Prompt\n",
        "prompt_text = f\"\"\"\n",
        "You are a helpful assistant.\n",
        "From the following text, extract the top 3 AI tools for singers in a simple numbered list:\n",
        "\n",
        "Text:\n",
        "{raw_result}\n",
        "\"\"\"\n",
        "\n",
        "# Use HumanMessage\n",
        "summary = llm.predict_messages([HumanMessage(content=prompt_text)])\n",
        "\n",
        "print(\"\\n=== Top 3 List ===\")\n",
        "print(summary.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hAFlXLXaDDmv"
      },
      "outputs": [],
      "source": [
        "# Wellness Chatbot: Q and A , not exactly like chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MBQfSRV7DDzh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "9f3f667f-49dd-4815-ba18-92ba7ad222f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3e5fbb32a638e20018.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3e5fbb32a638e20018.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "from dotenv import load_dotenv\n",
        "import gradio as gr\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env.txt')\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it in .env\")\n",
        "\n",
        "# Initialize tools\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7, max_tokens=500)\n",
        "\n",
        "# Wellness chatbot function\n",
        "def wellness_chatbot(category, user_input):\n",
        "    if not user_input.strip():\n",
        "        return \"Please enter your concern/question.\"\n",
        "\n",
        "    # Step 1: Combine category + user input into search query\n",
        "    query = f\"{category} wellness advice: {user_input}\"\n",
        "    raw_result = search.run(query)\n",
        "\n",
        "    # Step 2: Prompt for summarization\n",
        "    #prompt_text = f\"\"\"\n",
        "    #You are a helpful wellness assistant.\n",
        "    #Category: {category}\n",
        "    #User Query: {user_input}\n",
        "\n",
        "    #Based on the following text, give practical, safe, and easy-to-follow #advice.\n",
        "    #Keep it short (3â€“4 sentences).\n",
        "\n",
        "    #Text:\n",
        "    #{raw_result}\n",
        "    #\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Step 2: Build prompt dynamically\n",
        "    if category == \"General Question\":\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful assistant.\n",
        "        The user has asked a general question.\n",
        "\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Provide a clear, practical, and balanced answer.\n",
        "        Keep it simple, safe, and easy-to-follow (3â€“4 sentences).\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful wellness assistant.\n",
        "        Category: {category}\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Based on the following text, give practical, safe, and easy-to-follow advice.\n",
        "        Keep it short (3â€“4 sentences).\n",
        "\n",
        "        Text:\n",
        "        {raw_result}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    summary = llm.predict_messages([HumanMessage(content=prompt_text)])\n",
        "    return summary.content\n",
        "\n",
        "# Categories\n",
        "categories = [\"Hair Care\", \"Emotional & Mental Health\", \"Eyes\", \"General Question\"]\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Wellness & Productivity Chatbot\")\n",
        "    gr.Markdown(\"Ask me about **Hair, Mental Health, Eyes, or General Queries** \")\n",
        "\n",
        "    with gr.Row():\n",
        "        category = gr.Dropdown(choices=categories, label=\"Select Wellness Area\")\n",
        "        user_input = gr.Textbox(label=\"Your Question / Concern\")\n",
        "\n",
        "    output = gr.Textbox(label=\"Chatbot Response\", lines=6)\n",
        "\n",
        "    submit = gr.Button(\"Press Enter\")\n",
        "\n",
        "    submit.click(fn=wellness_chatbot, inputs=[category, user_input], outputs=output)\n",
        "\n",
        "# Launch\n",
        "#if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zHkuB_naDD3m"
      },
      "outputs": [],
      "source": [
        "# Chat bot With Memory Qand A : not chatbot exactly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env.txt')\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it in .env\")\n",
        "\n",
        "# Initialize tools\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7, max_tokens=500)\n",
        "\n",
        "# Initialize memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Wellness chatbot function with memory\n",
        "def wellness_chatbot(category, user_input):\n",
        "    if not user_input.strip():\n",
        "        return \"Please enter your concern/question.\"\n",
        "\n",
        "    # Run search\n",
        "    raw_result = search.run(f\"{category} wellness advice: {user_input}\")\n",
        "\n",
        "    # Build prompt dynamically\n",
        "    if category == \"General Question\" or not raw_result.strip():\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful wellness assistant.\n",
        "        The user has asked a general question or the search returned no useful info.\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Provide practical, safe advice in 3â€“4 sentences.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful wellness assistant.\n",
        "        Category: {category}\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        Based on the following text, give practical, safe advice in 3â€“4 sentences.\n",
        "        Text:\n",
        "        {raw_result}\n",
        "        \"\"\"\n",
        "\n",
        "    # Generate response using Groq\n",
        "    response = llm.predict_messages([HumanMessage(content=prompt_text)])\n",
        "\n",
        "    # Update memory\n",
        "    memory.chat_memory.add_user_message(user_input)\n",
        "    memory.chat_memory.add_ai_message(response.content)\n",
        "\n",
        "    return response.content\n",
        "\n",
        "\n",
        "# Categories\n",
        "categories = [\"Hair Care\", \"Emotional & Mental Health\", \"Eyes\", \"General Question\"]\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Wellness & Productivity Chatbot\")\n",
        "    gr.Markdown(\"Ask me about **Hair, Mental Health, Eyes, or General Wellness**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        category_input = gr.Dropdown(choices=categories, label=\"Select Wellness Area\")\n",
        "        user_input = gr.Textbox(label=\"Your Question / Concern\")\n",
        "\n",
        "    output = gr.Textbox(label=\"Chatbot Response\", lines=6)\n",
        "    submit = gr.Button(\"Get Wellness Advice\")\n",
        "    submit.click(fn=wellness_chatbot, inputs=[category_input, user_input], outputs=output)\n",
        "\n",
        "# Launch in Colab with shareable link\n",
        "demo.launch(share=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "UuLj6FThPwqs",
        "outputId": "001015e9-0d5a-4708-efa1-622600e59e2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4112525483.py:19: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://14e9deb4f1d914fa51.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://14e9deb4f1d914fa51.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of a single Textbox, use Chatbot()"
      ],
      "metadata": {
        "id": "ZWxW5rVBQ6RC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real Chatbot : Your Question / Concern  screen-> no clearenace"
      ],
      "metadata": {
        "id": "Oh-Z_hb9Q8CA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env.txt')\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it in .env\")\n",
        "\n",
        "# Initialize tools\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7, max_tokens=500)\n",
        "# Initialize memory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Initialize search tool\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Global conversation history for Gradio\n",
        "chat_history = []\n",
        "\n",
        "# Function for conversational chatbot\n",
        "def wellness_chatbot(category, user_input):\n",
        "    global chat_history\n",
        "    if not user_input.strip():\n",
        "        return chat_history\n",
        "\n",
        "    # Run search\n",
        "    raw_result = search.run(f\"{category} wellness advice: {user_input}\")\n",
        "\n",
        "    # Build prompt dynamically\n",
        "    if category == \"General Questions\" or not raw_result.strip():\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful assistant.\n",
        "        The user has asked a general question or the search returned no useful info.\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Provide practical, safe advice in 3â€“4 sentences.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful wellness assistant.\n",
        "        Category: {category}\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        Based on the following text, give practical, safe advice in 3â€“4 sentences.\n",
        "        Text:\n",
        "        {raw_result}\n",
        "        \"\"\"\n",
        "\n",
        "    # Get response from Groq\n",
        "    response = llm.predict_messages([HumanMessage(content=prompt_text)])\n",
        "\n",
        "    # Update memory\n",
        "    memory.chat_memory.add_user_message(user_input)\n",
        "    memory.chat_memory.add_ai_message(response.content)\n",
        "\n",
        "    # Update chat history for Gradio chatbot\n",
        "    chat_history.append((user_input, response.content))\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "# Categories\n",
        "categories = [\"Hair Care\", \"Emotional & Mental Health\", \"Eyes\", \"General Questions\"]\n",
        "\n",
        "# Gradio UI with Chatbot component\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Wellness & Productivity Chatbot \")\n",
        "    gr.Markdown(\"Ask me about Hair, Mental Health, Eyes, or General Wellness.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        category_input = gr.Dropdown(choices=categories, label=\"Select Wellness Area\")\n",
        "        user_input = gr.Textbox(label=\"Your Question / Concern\")\n",
        "\n",
        "    chatbot_output = gr.Chatbot(label=\"Chatbot Conversation\")\n",
        "\n",
        "    submit = gr.Button(\"Send\")\n",
        "    submit.click(fn=wellness_chatbot, inputs=[category_input, user_input], outputs=chatbot_output)\n",
        "\n",
        "# Launch in Colab\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "FkGuxBZzQ8mZ",
        "outputId": "ac785956-2d88-4d53-b970-01de0fb6f2b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1837209106.py:86: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot_output = gr.Chatbot(label=\"Chatbot Conversation\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://60e28425176d78209f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://60e28425176d78209f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wellness chatbot with memory # Real Chatbot : Your Question / Concern  screen-> no clearenace"
      ],
      "metadata": {
        "id": "QV9_O_UcB9Lm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env.txt')\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it in .env\")\n",
        "\n",
        "# Initialize tools\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7, max_tokens=500)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Global conversation history for Gradio\n",
        "chat_history = []\n",
        "\n",
        "# Function for conversational chatbot\n",
        "def wellness_chatbot(category, user_input):\n",
        "    global chat_history\n",
        "    if not user_input.strip():\n",
        "        return chat_history\n",
        "\n",
        "    # Run search\n",
        "    raw_result = search.run(f\"{category} wellness advice: {user_input}\")\n",
        "\n",
        "    # Build prompt dynamically\n",
        "    if category == \"General Questions\" or not raw_result.strip():\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful assistant.\n",
        "        The user has asked a general question or the search returned no useful info.\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Provide practical, safe advice in 3â€“4 sentences.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful wellness assistant.\n",
        "        Category: {category}\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        Based on the following text, give practical, safe advice in 3â€“4 sentences.\n",
        "        Text:\n",
        "        {raw_result}\n",
        "        \"\"\"\n",
        "\n",
        "    # Get response from Groq\n",
        "    response = llm.predict_messages([HumanMessage(content=prompt_text)])\n",
        "\n",
        "    # Update memory\n",
        "    memory.chat_memory.add_user_message(user_input)\n",
        "    memory.chat_memory.add_ai_message(response.content)\n",
        "\n",
        "    # Update chat history for Gradio chatbot\n",
        "    chat_history.append((user_input, response.content))\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "# Categories\n",
        "categories = [\"Hair Care\", \"Emotional & Mental Health\", \"Eyes\", \"Heart Wellness\", \"Brain Wellness\", \"General Questions\"]\n",
        "\n",
        "# Gradio UI with Chatbot component\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸŒ± Wellness & Productivity Chatbot\")\n",
        "    gr.Markdown(\"Ask me about Hair, Mental Health, Eyes, Heart, Brain, or General Wellness.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        category_input = gr.Dropdown(choices=categories, label=\"Select Wellness Area\", value=\"General Questions\")\n",
        "        user_input = gr.Textbox(label=\"Your Question / Concern\")\n",
        "        submit = gr.Button(\"Send\")  # Button next to the question\n",
        "\n",
        "    chatbot_output = gr.Chatbot(label=\"Chatbot Conversation\")\n",
        "\n",
        "    submit.click(\n",
        "    fn=wellness_chatbot,\n",
        "    inputs=[category_input, user_input],\n",
        "    outputs=[chatbot_output]  # second output clears the textbox\n",
        ")\n",
        "\n",
        "# Launch in Colab or local\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "yn8ZUgZrR8oa",
        "outputId": "dd508a66-5262-4b6f-df7c-b841c64f05a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1010648084.py:85: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot_output = gr.Chatbot(label=\"Chatbot Conversation\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b31b745fcfa340048b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b31b745fcfa340048b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Wellness Chatbot: clerance on Ques window"
      ],
      "metadata": {
        "id": "Ni1g8IY2KWLq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env.txt')\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it in .env\")\n",
        "\n",
        "# Initialize tools\n",
        "search = DuckDuckGoSearchRun()\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7, max_tokens=500)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Global conversation history for Gradio\n",
        "chat_history = []\n",
        "\n",
        "# Function for conversational chatbot\n",
        "def wellness_chatbot(category, user_input):\n",
        "    global chat_history\n",
        "    if not user_input.strip():\n",
        "        return chat_history, \"\"\n",
        "\n",
        "    # Run search\n",
        "    raw_result = search.run(f\"{category} wellness advice: {user_input}\")\n",
        "\n",
        "    # Build prompt dynamically\n",
        "    if category == \"General Questions\" or not raw_result.strip():\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful assistant.\n",
        "        The user has asked a general question or the search returned no useful info.\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Provide practical, safe advice in 3â€“4 sentences.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt_text = f\"\"\"\n",
        "        You are a helpful wellness assistant.\n",
        "        Category: {category}\n",
        "        User Query: {user_input}\n",
        "\n",
        "        Conversation so far:\n",
        "        {memory.chat_memory.messages}\n",
        "\n",
        "        Based on the following text, give practical, safe advice in 3â€“4 sentences.\n",
        "        Text:\n",
        "        {raw_result}\n",
        "        \"\"\"\n",
        "\n",
        "    # Get response from Groq\n",
        "    response = llm.predict_messages([HumanMessage(content=prompt_text)])\n",
        "\n",
        "    # Update memory\n",
        "    memory.chat_memory.add_user_message(user_input)\n",
        "    memory.chat_memory.add_ai_message(response.content)\n",
        "\n",
        "    # Update chat history for Gradio chatbot\n",
        "    chat_history.append((user_input, response.content))\n",
        "\n",
        "    # Return chat history AND empty string to clear input\n",
        "    return chat_history, \"\"\n",
        "\n",
        "# Categories\n",
        "categories = [\"Hair Care\", \"Emotional & Mental Health\", \"Eyes\", \"Heart Wellness\", \"Brain Wellness\", \"General Questions\"]\n",
        "\n",
        "# Gradio UI with Chatbot component\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸŒ± Wellness & Productivity Chatbot\")\n",
        "    gr.Markdown(\"Ask me about Hair, Mental Health, Eyes, Heart, Brain, or General Wellness.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        category_input = gr.Dropdown(choices=categories, label=\"Select Wellness Area\", value=\"General Questions\")\n",
        "        user_input = gr.Textbox(label=\"Your Question / Concern\")\n",
        "        submit = gr.Button(\"Send\")  # Button next to the question\n",
        "\n",
        "    chatbot_output = gr.Chatbot(label=\"Chatbot Conversation\")\n",
        "\n",
        "    submit.click(\n",
        "        fn=wellness_chatbot,\n",
        "        inputs=[category_input, user_input],\n",
        "        outputs=[chatbot_output, user_input]  # second output clears the textbox\n",
        "    )\n",
        "\n",
        "# Launch in Colab or local\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "P48UbEpHS_dD",
        "outputId": "c42b7025-7ad6-43ac-8f5c-9503ccdb9f11"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3950469045.py:86: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot_output = gr.Chatbot(label=\"Chatbot Conversation\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dd17d03fd18ee54001.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dd17d03fd18ee54001.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yufSQsYjS_nx"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}